---
title: "ED project"
author: "Jing Yeh, Saurav Sathnarayan"
date: "2024-09-03"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(scales)
library(gridExtra)
library(knitr)
library(xtable)
```

# CHANGES

\begin{tabular}{l|r|r|r}
\hline
  & CPU & MEMORY & OPERATING SYSTEM\\
\hline
Ishango PC &  9th Gen Intel® Core™ i3-9100  & 8,0 GB &  Ubuntu 22.04\\
\hline
MidddleTROld & 9th Gen Intel(R) Core(TM) i5-9500 CPU & 8,0 GB &  Windows 10\\
\hline
MiddleTRNew & 12th Gen Intel(R) Core(TM) i5-13400 & 16,0 GB &  Windows 10\\
\hline
ScilabB &  12th Gen Intel(R) Core(TM) i5-12400 &  16,0 GB  &  Windows 10\\
\hline
Surface &  9th Gen Intel(R) Core(TM) i5-8250 CPU &  16,0 GB  &  Windows 10\\
\hline
ASUS (i7-5500u) &  5th Gen Intel(R) Core(TM) i7-5500U CPU &  6,0 GB  &  Windows 10\\
\hline
ScilabD &  10th Gen Intel(R) Core(TM) i5-10500 &  16,0 GB  &  Windows 10\\
\hline
LT &  9th Gen Intel(R) Core(TM) i5-9400f &  8,0 GB  &  Windows 10\\
\hline
HP (i5-7200) &  7th Gen Intel(R) Core(TM) i5-7200 &  8,0 GB  &  Windows 10\\
\end{tabular}


# DIAGRAM
```{r echo=FALSE, results='asis'}
df <- read.csv('diagram.csv',header = TRUE)
print(xtable(df, type = "latex"))
```



_things need to change and edit_
\
1. add page numbers
\
2. might need to add new pages/headings depending on project length.
\
3. Add title page?

\newpage



```{r include=FALSE}
#page 1
```

# Introduction

The goal of this experiment is to identify the programming language that delivers the fastest execution time when calculating a value of $\pi$ with respect to Leibiniz formula. $$\sum_{n=0}^{\infty} (-1)^n/(2n+1)$$

With the increasing demand for high-performance applications, understanding which programming languages offer superior speed in terms of execution is crucial for developers, especially in domains requiring real-time processing, large-scale data analysis, and resource-intensive computations.
\
This problem will focus on evaluating a selection of popular programming languages, including but not limited to C++, C, R, Python, Java, and Ruby. The evaluation will consider how quickly a value of pi can be calculated by applying leibiniz formula up to 100000000 terms.
\

#### Compiled Language:
\
In a compiled language, the source code is translated into machine code by a compiler before execution. This machine code, often called an executable, can be run directly by the computer's hardware.
\
Compiled programs typically run faster since they are already in machine language, which the computer's processor can execute directly.
\
Examples: C, C++, Rust, and Go are examples of compiled languages.

#### Interpreted Language:
\
In an interpreted language, the source code is executed line-by-line by an interpreter at runtime. The interpreter reads the code, translates it into machine code, and executes it on the fly.
\
Interpreted programs generally run slower than compiled ones because the translation happens during execution.
\
Examples: Python, JavaScript, Ruby, and PHP are examples of interpreted languages.

#### Key Differences:
Compiled languages require a compilation step that produces an executable, while interpreted languages are executed directly by an interpreter.
\
 Compiled languages tend to have better performance due to the pre-compiled nature of the code, whereas interpreted languages are more flexible but slower due to the runtime translation.
\
Some languages, like Java, use a combination of both techniques, where the code is first compiled into an intermediate form (bytecode) and then interpreted just-in-time (JIT) at runtime.
\
_still need to edit this_


\newpage


```{r include=FALSE}
#page 2
```

# Objectives
_I don't think we need to restate our objectives here, since we've already explained it in the Introduction_

Our main objective is to test the following hypothesis: $$H_0 : \alpha_i = 0$$ $$H_1 :\text{at least of } \alpha_i \neq 0$$
$\text{For some } i = 1,2...6$

#### Planned comparsions
\
1. Which language is the fastest?
\
2. Comparsions between C and C++ and other languages
\
3. Do complied languages run faster than interpreted languages ?
\
4. Is R (vectorised Language) faster than non-vectorised language when performing calculations?
\
\newpage


```{r include=FALSE}
#page 3
```
# Methods


#### Sources of Variation
\
Our experimental units are PCs, which are available in the following Laboratories: Ishango Senior Computing Laboratory(Ishango) , Science Laboratory B (Scilab B) and Middle Campus Library Training Room (MiddleTROld and MiddleTRNew).

#### PC Specificiations
\

\begin{tabular}{l|r|r|r}
\hline
  & CPU & MEMORY & OPERATING SYSTEM\\
\hline
Ishango PC &  9th Gen Intel® Core™ i3-9100  & 8,0 GB &  Ubuntu 22.04\\
\hline
MidddleTROld & 9th Gen Intel(R) Core(TM) i5-9500 CPU & 8,0 GB &  Windows 10\\
\hline
MiddleTRNew & 12th Gen Intel(R) Core(TM) i5-13400 & 16,0 GB &  Windows 10\\
\hline
ScilabB &  12th Gen Intel(R) Core(TM) i5-12400 &  16,0 GB  &  Windows 10\\
\hline
Surface &  9th Gen Intel(R) Core(TM) i5-8250 CPU &  16,0 GB  &  Windows 10\\
\hline
ASUS laptop &  5th Gen Intel(R) Core(TM) i7-5500U CPU &  6,0 GB  &  Windows 10\\
\end{tabular}

\


Due to the differences in specifications in the PCs, we have decided to block for the hardware setups,
as well as operating systems (please refer to pilot experiment), to reduce experimental error variance between the experiment units. 
 

#### Treatment Factor
Our treatment Factors are 6 programming languages: C, C++, Java, Python, R and Ruby. To apply each factor, we will run Leibiniz formula a billion times to get an observation. Our response $Y_{ij}$ is the amount of seconds taken to compute leibinz formula a billion times.

#### Randomisation Procedure:
In theory, experimental units must be completely independent from eah other, which implies that using different machines for each treatment would be ideal. In practice, however, this is not feasible as we only have access to a limited range of hardware setups, and a limited number of machines for some setups. Therefore, we applied the treatments on the same machines, but made sure that caches have been cleared in every run, as well as randomised the order in which we applied the treatments to minimise the impact of confounding factors. This is done through the **shuffle** method that comes with Python's random module.
```{python3 eval=FALSE}
random.shuffle([c, cpp, java, python, ruby, r ])
```


\newpage


```{r include=FALSE}
#page 5
```

# Pilot experiment
```{r include=FALSE}
# Set up R for pilot study

```

### Scale of Experiment
As mentioned in the introduction, we aim to investigate the speed of various programming languages when used to perform large amount of computation. To start with, we conducted a small scale pilot experiment. This is based on the "first explore then confirm" strategy described in [1] and [4].
 
Since the number of treatments we apply in this experiment does not significantly impact the time and cost required, we apply all six treatments. However, as computers of different specifications are harder to come by, we will only use 3 different hardware setup for this pilot study.

### Problem: Runtimes of Programming Langugaes are not Normally Distributed
Upon inspecting the qqnorm plots of the runtime of all programming languages on the same machine, we discovered that the runtime of languages tend to not follow a normal distribution, even when the sample size is fairly large (n = 100)

To address this, we ran the program 15 times per sample for each programming language, and repeated the process 30 times. By the Central Limit Theorem (CLT), the distribution of sample means is approximately normal [2]. If we assume sample means to be normally distributed, the mean of the distribution of sample means is then an unbiased estimator for the true run time of each programming language[2], which we take as a single observation.

The process described above is automated using the following command:
```{eval=FALSE}
python3 run.py main 100000000 15 30
```


```{r, echo=FALSE, out.height="45%"}
setwd("./speed-comparison-master/data/")
ishango.before <- read.csv("ishango/noCLT/ishango.csv")
ishango.before.long <- pivot_longer(ishango.before, cols=everything(), names_to="language", values_to="runtime")
before <- ggplot(ishango.before.long, aes(sample=(runtime)))+
  stat_qq(col="green")+
  stat_qq_line(col="blue")+
  facet_wrap(~language, scales="free")+
  labs(x="quantiles", y="ms", title="Using One Sample of Size 100")+
  theme(axis.text.x = element_text(size=6))

ishango.after <- read.csv("ishango/fifteen30/ishango_mean.csv")

ishango.after.long <- pivot_longer(ishango.after, cols=everything(), names_to="language", values_to="runtime")
after <- ggplot(ishango.after.long, aes(sample=(runtime)))+
  stat_qq(col="coral")+
  stat_qq_line(col="blue")+
  facet_wrap(~language, scales="free")+
  labs(x="quantiles", y="ms", title="Using 30 Samples of Size 15")+
  theme(axis.text.x = element_text(size=6))

grid.arrange(before, after, ncol=2, nrow=1)
```


### Problem: Ensuring no Interactions between Blocking Factors and Treatment Factors
_todo: insert table for results_
```{r echo=FALSE}
setwd("./speed-comparison-master/data/")

pilot <- read.csv("pilotData.csv")
ttheme <- ttheme_minimal(base_size=10)
table <- tableGrob(pilot, them=ttheme)

pilot.long <- pivot_longer(pilot, cols=C:R, names_to = "language", values_to = "runtime")
plot <- ggplot(pilot.long, aes(x=language, y=log(runtime), group=Hardware, color=Hardware))+
  geom_point()+
  geom_line()+
  labs(title= "Interaction Graph",
       x= "Progamming Language",
       y= "Log Runtime")
grid.arrange(plot, table, ncol=1, nrow=2)
```
From the data collected, we observed that the results collected from Ishango do not follow the general trends established by the other three setups. Firstly, the hardware setup in Ishango lab is significantly less advance than MiddleTRNew. Yet, most programming languages tend to perform better on the Ishango machine. Secondly, to add to the first observation, not all programming languages perform better on the Ishango machine.

After further investigation, we learned that programming languages perform differently on various operating systems [4]. We hypothesised that this is likely the reason for the deviation, though further studies are needed to confirm this (we lack access to machines with the same hardware setup but run on different operating system).

Therefore, we added another constraint for selecting suitable machines: the machines must all run on Windows 10, as these machines are the most widely available.





\
_this is an exploratory study, so no need to list hypotheses (it's meant to generate hypotheses for the real study)_
\
_list our hypothesis here (is there a difference or not?)_
\
_anova table and conclusions_
\

\newpage


```{r include=FALSE}
#page 6
```
# Our Model and Analysis

Our model:
$$Y_{ij} = \mu + \alpha_i + \beta_j+ e_{ij}$$
$$ i = 1 ...a$$
$$ j = 1 ...b$$
where
$$\sum_{i=1}^a \alpha_i = \sum_{j=1}^b \beta_i =0 $$
and:

$$
\begin{aligned}
&\mu\hspace{35pt}  \text{overall mean} \\
&\alpha_i\hspace{35pt} \text{effect of }\, i^{th}\, \text{treatment}\\
&\beta_j\hspace{35pt} \text{effect of }\, j^{th}\, \text{block}\\
&e_{ij}\hspace{35pt} \text{random error of the observation}\\
\end{aligned}
$$

#### Analysis
```{r}


```

#### ANOVA

#### CONTRASTS


\newpage


```{r include=FALSE}
#page 7
```
# Summary and Conclusions

_draw conclusions here_
\
_explain any challenges possibly_
\
_explain how we would do it differently, to fix errors or mistakes_
\newpage

```{r include=FALSE}
#page 8
```
# References
_any references, textbook, code, people wh helped us._
\newpage

```{r include=FALSE}
#page 9
```
# Apenddix
_add important code here._
