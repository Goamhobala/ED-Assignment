
\documentclass[12pt,halfline,a4paper,]{ouparticle}

% Packages I think are necessary for basic Rmarkdown functionality
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyvrb}
\usepackage{framed}

% Link coloring
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={STA2005S - Experimental Design Assignment}
            }


%% To allow better options for figure placement
%\usepackage{float}

% Packages that are supposedly required by OUP sty file
\usepackage{amssymb, amsmath, geometry, amsfonts, verbatim, endnotes, setspace}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

% Macros for dealing with affiliations, footnotes, etc.
\makeatletter
\def\Newlabel#1#2#3{\expandafter\gdef\csname #1@#2\endcsname{#3}}

\def\Ref#1#2{\@ifundefined{#1@#2}{???}{\csname #1@#2\endcsname}}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

\newcommand*\ifcounter[1]{%
  \ifcsname c@#1\endcsname
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
}

\newcommand*\thanksbycode[1]{%
  \ifcounter{FNCT@#1}
    {\samethanks[\value{FNCT@#1}]}
    {\thanks{\Ref{FN}{#1}}\newcounter{FNCT@#1}\setcounter{FNCT@#1}{\value{footnote}}}
}

% Create labels for Addresses if the are given in Elsevier format

% Create labels for Footnotes if the are given in Elsevier format

% Part for setting citation format package: natbib

% Part for setting citation format package: biblatex


% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% From pandoc table feature
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}

% Pandoc citation processing
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{float} \floatplacement{figure}{H} \usepackage{caption} \captionsetup[figure]{font=scriptsize}

\begin{document}

\title{STA2005S - Experimental Design Assignment}

\author{%
%
% Code for old style authors field
%
% Add \and if both authors and author
%
%
% Code for new (elsevier) style author field
\name{Jing Yeh}
\address{\Ref{ADR}{University of Cape Town}}
%
\email{\href{mailto:yhxjin001@myuct.ac.za}{yhxjin001@myuct.ac.za}}%
%
%
%
\and
\name{Saurav Sathnarayan}
\address{\Ref{ADR}{University of Cape Town'}}
%
\email{\href{mailto:sthsau01001@myuct.ac.za}{sthsau01001@myuct.ac.za}}%
%
%
%
%
}

\abstract{}

\date{2024-09-14}

\keywords{}

\maketitle



\newpage

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Computation has played a major role in human history ever since people
began living in cities. The need to calculate taxes motivated the
invention of various computing devices that aided such computations,
such as the Sumerian abacus, invented in Babylon at around 2500BC
{[}7{]}. In the 21st century, the capability of our digital computing
devices have vastly surpassed the capacity of those proto-computers, but
so has our need for computational power. Everything in our daily life
requires some form of computers: from our phones, cars, to even our
refrigerators (side note: initially, Java was invented for
refrigerators).

However, with large computation capability comes complexity in the
design of these devices: to speak plainly, they are damn difficult to
use. Computer scientists have therefore invented numerous
\emph{programming languages} that allow us to harness the power of these
devices more easily.

Nowadays, programming languages have become the primary medium for
instructing computers to perform our increasingly complex tasks.
Understanding which programming languages offer superior execution speed
is therefore crucial for developers, especially in domains requiring
real-time processing, large-scale data analysis, and other
resource-intensive computations. The goal of this experiment is to
identify such languages that deliver the fastest execution time.

\hypertarget{compiled-vs-interpreted-languages}{%
\subsection{Compiled vs Interpreted
Languages}\label{compiled-vs-interpreted-languages}}

\hypertarget{compiled-language}{%
\paragraph{Compiled Language:}\label{compiled-language}}

\hfill\break
In a compiled language, the source code is translated into machine code
by a compiler before execution. This machine code, often called an
executable, can be run directly by the computer's hardware.\\
Compiled programs typically run faster since they are already in machine
language, which the computer's processor can execute directly.\\
Examples: C, C++, Rust, and Java are examples of compiled languages.

\hypertarget{interpreted-language}{%
\paragraph{Interpreted Language:}\label{interpreted-language}}

\hfill\break
In an interpreted language, the source code is executed line-by-line by
an interpreter at runtime. The interpreter reads the code, translates it
into machine code, and executes it on the fly.\\
Interpreted programs generally run slower than compiled ones because the
translation happens during execution.\\
Examples: Python, JavaScript, Ruby, and R are examples of interpreted
languages.

\hypertarget{key-differences}{%
\paragraph{Key Differences:}\label{key-differences}}

Compiled languages require a compilation step that produces an
executable, while interpreted languages are executed directly by an
interpreter.\\
Compiled languages tend to have better performance due to the
pre-compiled nature of the code, whereas interpreted languages are more
flexible but slower due to the runtime translation.

\hypertarget{distribution-of-execution-times}{%
\subsection{Distribution of Execution
Times:}\label{distribution-of-execution-times}}

Since existing literature on the execution times of programming
languages when applying Leibniz's formula is limited, we performed an a
priori test to gauge the execution time for the programming languages we
planned on experimenting with. We performed 500 approximations using the
algorithm for each programming language and obtained the following
jittered graph.

\begin{figure}[H]
\includegraphics[width=1\linewidth]{skeleton_files/figure-latex/figPrior-1} \caption{Runtimes of Programming Languages of Interest When Applying Leibniz's Formula up to 100 million terms}\label{fig:figPrior}
\end{figure}

We can observe that C and C++ seem to be the fastest languages, though
further analyses are needed. We can also see from the
Quantile-Quantile(Q-Q) plots that the execution times are clearly not
normally distributed. \newpage

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{setting}{%
\subsection{Setting}\label{setting}}

This study was mostly conducted at the University of Cape Town,
utilising the computers available on campus. We found that there are
only 5 different hardware setups available. Thus, to supplement the
range of our hardware setups, we also borrowed machines of 2 more
hardware setups from our friends.

\hypertarget{approximation-of-pi}{%
\subsection{\texorpdfstring{Approximation of
\(\pi\)}{Approximation of \textbackslash pi}}\label{approximation-of-pi}}

The number \(\pi\), the ubiquitous and equally mysterious irrational
number, has been fascinating the humankind since time immemorial.
Mathematicians from 4000 years ago to the present day have devised
various methods to get closer to the true value of \(\pi\). One such
method is using Leibniz's formula: \[
4 \left( 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} ±... \right) = \sum_{k=0}^{\infty}\frac{(-1)^k}{2k+1}
\] Leibniz, whom the formula is named after, proved that the series
above eventually converges to \(\pi\). That is: \[
\pi = 4 \left( 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9} ±... \right) = \sum_{k=0}^{\infty}\frac{(-1)^k}{2k+1}.
\] We applied this algorithm in 6 programming languages, including 3
compiled languages: C, C++, Java, and 3 interpreted languages: Python,
R, Ruby, up to a \(100 \times 10^6\) terms.

\hypertarget{sampling-procedure}{%
\subsection{Sampling Procedure}\label{sampling-procedure}}

Since existing literature tend to suggest that execution times of
programming languages are not normally distributed, we perform a priori
tests to confirm that none of our languages has normally distributed
runtime. This is an issue as it prevented us to apply anova models. To
address this, we applied the Central Limit Theorem(CLT) to obtain a
normal distribution for the average execution times. We ran the program
15 times per sample for each programming language, and repeated the
process 30 times. Applying CLT, it is relatively safe to assume the
distribution of sample means is approximately normal {[}2{]}. If we
assume sample means to be normally distributed, the mean of the
distribution of sample means is then an unbiased estimator for the true
run time of each programming language{[}2{]}, which we will take as a
single observation. (Note: We arrived at the number 15 through trial and
error, and 30 from {[}8{]})

\hypertarget{sources-of-variation}{%
\subsection{Sources of Variation}\label{sources-of-variation}}

\hypertarget{treatments}{%
\paragraph{Treatments:}\label{treatments}}

We have 6 treatment factors, which are the programming languages we
applied the algorithm to. Each treatment has one level (applying the
formula up to \(100 \times 10^6\) terms). We selected this particular
level because it is the largest, practical number of terms we could
apply with our hardware setups (For some setups, it may take up to 4
hours to arrive at a single observation), and fewer terms imply larger
relative measurement error {[}7{]}. We cannot include more levels
because in the existing literature, most studies of such kind choose to
run all languages on the same machine. However, since we would like to
avoid pseudo replication as much as possible we used one machine per
observation. The downside of this approach is that we do not have
sufficient machines to perform more than one levels.

\hypertarget{blocks}{%
\paragraph{Blocks:}\label{blocks}}

We know that the hardware setup of a computer can significantly affect
its speed, and there fore the execution time of our algorithm. We also
know that, two computers with the same hardware setup should perform
relatively the same, provided that they run on the same operating
system, and no major damage has been done. This motivated us to block
for the hardware setup of computers, our experimental units.

\hypertarget{experimental-units}{%
\subsection{Experimental Units:}\label{experimental-units}}

As mentioned earlier, we would like to avoid pseudo replication as much
as possible. Therefore, we deviated from the tradition of running all
programming languages on the same machine, and test only one language
per machine. Our experimental units are therefore the individual
machines we ran each test on.

\hypertarget{randomisation-procedure}{%
\subsection{Randomisation Procedure}\label{randomisation-procedure}}

We first ordered the computers belonging to each block from 1 to 6. We
then used the random number generator from Python's \emph{random} module
to randomly shuffle, and thus producing a permutation of the list, {[}C,
C++, Java, Python, Ruby, R{]}. The index of each programming language in
the permutation would then be paired to the computer with the same
assigned number.

\hypertarget{planned-comparisons}{%
\subsection{Planned Comparisons}\label{planned-comparisons}}

We planned to conduct pairwise comparisons on all treatments. That is, a
total of \(6 \choose 2 = 15\) comparisons. It would also serve our
objective by comparing the efficiency of compiled languages (C, C++,
Java) and interpreted languages (Python, Ruby, R), as the latter are
oftentimes easier to program with.

\hypertarget{pilot-experiment}{%
\subsection{Pilot Experiment}\label{pilot-experiment}}

We followed this direction and performed an pilot study to obtain the
following execution times of programming languages on 4 hardware setups

\begin{verbatim}
## Warning in read.table(file = file, header = header, sep = sep, quote = quote, :
## incomplete final line found by readTableHeader on 'pilotData.csv'
\end{verbatim}

\begin{figure}[H]
\includegraphics[width=1\linewidth]{skeleton_files/figure-latex/figPilot-1} \caption{Interaction Graph of Programming Languages and Blocks}\label{fig:figPilot}
\end{figure}

From the data collected, we observed that the results collected from
Ishango do not follow the general trends established by the other three
setups. Firstly, the hardware setup in Ishango lab is significantly less
advance than MiddleTRNew. Yet, most programming languages tend to
perform better on the Ishango machine. Secondly, to add to the first
observation, not all programming languages perform better on the Ishango
machine.

After further investigation, we learned that programming languages
perform differently on various operating systems {[}4{]}. We
hypothesised that this is likely the reason for the deviation, though
further studies are needed to confirm this (we lack access to machines
with the same hardware setup but run on different operating system).

Therefore, we added another constraint for selecting suitable machines:
the machines must all run on Windows 10, as these machines are the most
widely available. \#\# Design We assume that: \[
e_{ij} \sim \mathcal{N}(0, \sigma^2)
\] We use the following anova model for our response variables:

\[
Y_{ij} = \mu + \alpha_i + \beta_j+ e_{ij}
\] \[
i = 1 ...a
\] \[
j = 1 ...b
\] With the following constraints: \[
\sum_{i=1}^a \alpha_i = \sum_{j=1}^b \beta_i =0 
\] Where: \[
\begin{aligned}
&\mu\hspace{35pt}  \text{overall mean} \\
&\alpha_i\hspace{35pt} \text{effect of }\, i^{th}\, \text{treatment}\\
&\beta_j\hspace{35pt} \text{effect of }\, j^{th}\, \text{block}\\
&e_{ij}\hspace{35pt} \text{random error of the observation}\\
\end{aligned}
\]

We also assume that each \(e_{ij}\) is independent to each other, which
allows us to assume that each \(Y_{ij}\) is also independent to each
other, and are normally distributed. If there are no blocking and
treatment effects, then: \[
Y_{ij} \sim \mathcal{N}(\mu, \sigma^2)
\] Otherwise, if there are blocking and treatment effects, then: \[
Y_{ij} \sim \mathcal{N}(\mu + \alpha_i + \beta_j, \sigma^2)
\] Below is the layout of the design

\begin{figure}[H]
\includegraphics[width=1\linewidth]{diagram} \caption{Diagram of the Design}\label{fig:unnamed-chunk-1}
\end{figure}
\newpage

\hypertarget{results}{%
\section{Results}\label{results}}

We performed the experiment described above on 7 different hardware
setups and applied all 6 treatments. Detailed tables for data and for
each hardware setup can be found in the appendix. The Analysis of
Variance (ANOVA) table is shown below:

\begin{longtable}[]{@{}lrrrrr@{}}
\toprule\noalign{}
& Df & Sum sq & Mean sq & F value & Pr(\textgreater F) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Language & 5 & 65.2112 & 13.0422 & 285.9459 & \textless{} 0.0001 \\
Hardware & 6 & 6.5717 & 1.0953 & 24.0136 & \textless{} 0.0001 \\
Residuals & 30 & 1.3683 & 0.0456 & & \\
\end{longtable}

\begin{figure}[H]
\includegraphics[width=1\linewidth]{skeleton_files/figure-latex/figAnova-1} \caption{The ANOVA table and Relavent Plots}\label{fig:figAnova}
\end{figure}

\hypertarget{verifying-model}{%
\subsection{Verifying Model}\label{verifying-model}}

We verified our model by observing the Fitted vs Residuals graph: the
residuals seem to spread out haphazardly, with no obvious patterns to be
discerned. This suggests homoscedasticity {[}7{]}. Also, the
Quantile-Quantile graph offers a fairly good fit, hinting that residuals
are normally distributed.

We further verified our assumptions by performing Shapiro Wilk test on
the residuals. We obtained a fairly large p-value of 0.7521, indicating
that we have little evidence for residuals not being normally
distributed. Further, we also got that the mean of the residuals is
approximately zero ( \(< 10^{-15}\) ), indicating that it is sensible to
assume \(e_{ij} \sim \mathcal{N}(0, \sigma^2)\)

\hypertarget{pairwise-comparisons}{%
\subsection{Pairwise Comparisons}\label{pairwise-comparisons}}

\begin{longtable}[]{@{}cccccc@{}}
\toprule\noalign{}
C & CPP & Java & Python & Ruby & R \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2.7381 & 2.72 & 3.118 & 3.7273 & 4.198 & 3.4101 \\
\end{longtable}

Given that we know our response variables are normally distributed, we
used Tukey's Method to construct 95\% confidence intervals that compare
the execution time of every possible pair of our 6 programming
languages. Sine we know the estimate of the standard deviation of
residuals, we can estimate the standard error (SE) of our treatment
means, and then find Tukey's Honestly Significant Difference(HSD): \[
\begin{aligned}
SE &= \frac{s}{\sqrt{b}}\\
&= \frac{0.0456}{\sqrt{13}}\\\\
HSD &= q_{6,30}^{0.05} \frac{s}{\sqrt{b}}\\
&= 4.3015 \times \frac{\sqrt{0.0456}}{\sqrt{13}}\\
&= 0.2535
\end{aligned}
\]

\begin{figure}[H]
\includegraphics[width=1\linewidth]{skeleton_files/table_tukey} \caption{Results of Tukey's Honestly Significance Difference Test. Values Greater than HSD are Highlighted in Blue}\label{fig:tableTukey}
\end{figure}

We can see, with 95\% confidence, that from the table of Tukey's HSD
tests that C and C++ have the fastest execution times than others when
performing the algorithm up to \(100 \times 10^6\) terms. The results
can be summarised as follows: \[
t(C) \approx t(C++) < t(Java) < t(R) < t(Python) < t(Ruby)
\] The p-values for relatively less significant results (p-value
\textgreater{} 0.005) are given below:\\
- R vs Python: 0.0173\\
- R vs Java: 0.0080

\hypertarget{compiled-vs-interpreted}{%
\subsection{Compiled vs Interpreted}\label{compiled-vs-interpreted}}

We were also interested in comparing the execution times of compiled
languages and interpreted languages. The contrast, \emph{L}, can be
stated as follows: \begin{align*}
L &= \frac{1}{3} (\mu_C + \mu_{C++} + \mu_{Java}) - \frac{1}{3}(\mu_{Python} + \mu_{Ruby} + \mu_{R})\\
\intertext{We can estimate the values relevant to the contrast as follows:}
\hat{L} &= \frac{1}{3} (\bar{y}_C + \bar{y}_{C++} + \bar{y}_{Java}) - \frac{1}{3}(\bar{y}_{Python} + \bar{y}_{Ruby} + \bar{y}_{R})\\
&= -0.9198 \\
\widehat{Var(\hat{L})} &= s^{2} \sum_{i=1}^{6} \frac{{h_i}^2}{n}\\
&= 0.0456\sum_{i=1}^{6}\frac{\frac{1}{9}}{7}\\
&= 0.004343\\
SE(\hat{L}) &= \sqrt{\widehat{Var(\hat{L})}}\\
 &= \sqrt{0.004343}\\
 &= 0.0659
\end{align*} We first note that \(t_{0.025}^{30} = 2.0422\). We will
then construct a 95\% confidence interval as follows: \begin{align*}
\hat{L}&\pm SE(\hat{L})\times t_{0.025}^{30}\\
-0.9198 &\pm 0.0659 \times 2.0422\\
\intertext{Thus, the 95\% Confidence interval is as follows: }
95\%C.I. &= (-1.0544 ,-0.7852)
\end{align*}

The mean log execution time of compiled languages is estimated to be
-1.05 log(ms) to -0.79 log(ms) shorter than the mean log execution time
of interpreted languages at 95\% confidence. We therefore have strong
evidence to suggests that compiled languages have shorter execution
times when applying Leibniz's formula up to a very large term. \newpage

\hypertarget{discussion-and-conclusion}{%
\section{Discussion and Conclusion}\label{discussion-and-conclusion}}

The experiment aimed to analyze the execution time of different
programming languages when applying Leibniz's formula across 7 hardware
setups and 6 treatments. The ANOVA results indicate significant
differences between the execution times of various languages, supporting
the hypothesis that compiled languages generally perform faster than
interpreted languages.\\
From the Tukey's HSD post-hoc tests, it is clear that C and C++ have the
fastest execution times, as reflected by their significantly lower mean
execution times compared to other languages. The compiled languages (C,
C++) outperformed Java, R, Python, and Ruby, suggesting a performance
gap that favors compiled over interpreted languages. Java, a
semi-compiled language, performed moderately well, trailing behind C and
C++ but significantly ahead of interpreted languages like Python and
Ruby.\\
The p-values between R and Python (0.0173) and R and Java (0.0080)
highlight some variability in performance across different language
types, although these differences are less significant than those
between compiled and interpreted languages. Moreover, the estimated log
execution times show a distinct advantage for compiled languages, with a
difference of -1.05 log(ms) to -0.79 log(ms), further validating that
compiled languages tend to be faster.\\
The ANOVA diagnostic plots (quantile-quantile and residuals vs.~fitted)
indicate a well-fitted model, with residuals demonstrating no major
deviations from normality and homoscedasticity, supporting the
robustness of the analysis.\\
Conclusion: The results of this experiment confirm that compiled
languages (C and C++) exhibit significantly faster execution times
compared to both semi-compiled (Java) and interpreted languages (R,
Python, Ruby). The performance gap between compiled and interpreted
languages becomes particularly evident with large-scale computations,
such as Leibniz's formula for a billion terms. Based on the ANOVA and
post-hoc analysis, we can conclude with 95\% confidence that compiled
languages provide a substantial performance advantage over interpreted
languages for this computational task. These findings can be useful for
developers when choosing a programming language for performance-critical
applications, especially those involving large iterative computations.

\newpage

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{pc-specificiations}{%
\paragraph{PC Specificiations}\label{pc-specificiations}}

\hfill\break
\% latex table generated in R 4.3.1 by xtable 1.8-4 package \% Sat Sep
14 23:31:40 2024

\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & PC & CPU & RAM & OS \\ 
  \hline
1 & Ishango PC &  9th Gen Intel® Core™ i3-9100  &  8.0 GB  & Ubuntu 22.04 \\ 
  2 & MidddleTROld &  9th Gen Intel(R) Core(TM) i5-9500 CPU  &  8.0 GB  &   Windows 10 \\ 
  3 & MiddleTRNew  &  12th Gen Intel(R) Core(TM) i5-13400  &  16.0 GB  &   Windows 10 \\ 
  4 & ScilabB  &   12th Gen Intel(R) Core(TM) i5-12400  &   16.0 GB   &   Windows 10 \\ 
  5 & Surface  &   9th Gen Intel(R) Core(TM) i5-8250 CPU  &   16.0 GB   &   Windows 10 \\ 
  6 & ASUS (i7-5500u)  &   5th Gen Intel(R) Core(TM) i7-5500U CPU  &   6.0 GB   &   Windows 10 \\ 
  7 & ScilabD  &   10th Gen Intel(R) Core(TM) i5-10500  &   16.0 GB   &   Windows 10 \\ 
  8 & LT  &   9th Gen Intel(R) Core(TM) i5-9400f  &   8.0 GB   &   Windows 10 \\ 
  9 & HP (i5-7200)  &   7th Gen Intel(R) Core(TM) i5-7200  &   8.0 GB   &   Windows 10 \\ 
   \hline
\end{tabular}
\caption{Table of Pcs used and their respective specifications} 
\end{table}

\% latex table generated in R 4.3.1 by xtable 1.8-4 package \% Sat Sep
14 23:31:40 2024

\begin{table}[ht]
\centering
\begin{tabular}{rlrrrrrr}
  \hline
 & Hardware & C & CPP & Java & Python & Ruby & R \\ 
  \hline
1 & MiddleTROld & 3.13 & 3.13 & 3.53 & 3.90 & 4.42 & 3.75 \\ 
  2 & MiddleTRNew & 2.40 & 2.41 & 2.88 & 3.50 & 3.91 & 3.26 \\ 
  3 & ScilabB & 2.61 & 2.57 & 2.86 & 3.51 & 3.93 & 3.25 \\ 
  4 & ASUS(i5) & 2.61 & 2.61 & 3.09 & 3.82 & 4.35 & 3.30 \\ 
  5 & HP(i5-7200) & 2.56 & 2.56 & 3.07 & 3.82 & 4.30 & 3.29 \\ 
  6 & ScilabD & 2.68 & 2.66 & 2.96 & 3.66 & 4.08 & 3.37 \\ 
  7 & LT & 2.76 & 2.68 & 3.01 & 3.71 & 4.12 & 3.40 \\ 
   \hline
\end{tabular}
\caption{Table of data used for analysis} 
\end{table}

\newpage

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-braun_2022_is}{}}%
Braun, Javen. 2022. {``Is Linux Faster Than Windows? Speed Comparison \&
Analysis.''} Linux JournalDigital.
\url{https://www.linuxjournaldigital.com/is-linux-faster-than-windows/}.

\leavevmode\vadjust pre{\hypertarget{ref-dean_2006_design}{}}%
Dean, Angela M, and Daniel Voss. 2006. \emph{Design and Analysis of
Experiments}. Springer Science \& Business Media.

\leavevmode\vadjust pre{\hypertarget{ref-greenwood_2021_intermediate}{}}%
Greenwood, Mark C. 2021. \emph{Intermediate Statistics with r}.

\leavevmode\vadjust pre{\hypertarget{ref-juritz_2023_design}{}}%
Juritz, J, F Little, and B Erni. 2023. \emph{Design of Experiment:
Course Notes for STA2005S}. University of Cape Town.

\leavevmode\vadjust pre{\hypertarget{ref-mavuso_2019_order}{}}%
Mavuso, Melusi, and Yuri Robbertze. 2019. \emph{Order Out of Chaos i and
II: STA2004F Notes}. University of Cape Town.

\end{CSLReferences}






\end{document}
